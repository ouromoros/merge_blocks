# 题目

定义‘数据块’为有序数组, 若干个数据块储存在单个 SSD 上，总大小 1TB, 请给出对这若干个数据块的全局排序算法。
要求内存使用不超过 16G, 并在多核环境下的尽可能的优化排序速度。

提示: 有序数据块可以当做是 int64 数组。

(数据块的大小为1MB~100MB)

# 分析

数据块的个数为10^4到10^6之间，内存的大小为16GB，因此若要在一次IO读写内使用外部排序完成的话，每个数据块可以使用的缓存大小约为
16KB~1.6MB之间。程序运行的时间主要应为SSD读写的时间，因此首先需要考虑这方面的优化。

假设SSD的读写速度为500MB/s，每个读、写命令的延迟时间为0.0001s，那么在16KB的缓存下读写速度约为 16KB / (0.0001 + 16 / 1024 / 500)，
约为120MB/s，小于500MB/s的一半，在这种情况下为了缩短整体的读写时间，我们考虑可以分两次进行数据块的*合并*，首先将小的数据块合并成大小适中
的数据块，最后再将这些数据块合并成最终的结果，在这种策略下虽然总共会进行两遍读写，但花费的时间总共将比一次外部排序的情况少。选择两阶段的合并还是
一次合并主要取决于数据块的数量（每个数据块可以使用的缓存大小），阈值大约在10^5左右，在实际机器上测试之前，我们可以大致决定当数据块数量大于
10^5时采用一次外部排序，而当数据块数量小于10^5时采用两阶段的排序。

## 两阶段的合并算法

在一次外部排序的效率较低（每个数据块可以分配的缓存大小过小时），我们首先将数据块分为多组，将每一组数据块合并为一个新的大小适中的数据块，最后
再使用一次外部排序将这些新的数据块合并为一个结果，这样我们可以有效的减少每一次合并操作中数据块的总数，从而可以增加在运算过程中每个数据块可以
可以使用的缓存大小，充分发挥硬盘的读写性能，从而达到缩短整体运行时间的目的。

第一次合并的过程中我们可以采取传统的外部排序方式，也可以尝试在不增加IO读写次数的情况下做一些优化。由于我们有16GB的内存，因此我们其实可以采取每次将要合并
的数据块全部读入内存然后合并的方法，归并排序不做优化的情况下大概会使用额外的一倍大小的内存空间（可以进行优化），这样我们每次可以合并大小约为8GB的数据块，
合并后的数据块数量为1024GB/8GB=256个，这个数量远远小于我们估计的阈值10^5，因此这样做是可以达到增加缓存大小以提升IO读取效率的目的的。

## 并行的归并排序算法

我们采用N路归并排序来进行排序，实际上就是使用堆来合并多个有序数组，为了利用多核的性能，我们首先将这些有序数组分为k组（k设置为CPU核的数量），
然后对每一组启动一个goroutine运行*归并*算法，最后将k个合并完成的数组合并为最终的结果。

> 这里用的算法只分了一次组，实际上我们还可以先将其分为k组，然后把分完的每组再分为m组，并递归的对其进行归并，传统的归并算法是每一次分为两组，并分到最小单位为止。分多次组的问题在于会增加
总的访存次数，但可以让并行的粒度更细，且可以避免堆的额外开销，实际上要如何达到最快的速度还需要更多的性能测试，也取决于具体的硬件条件，这里由于时间限制只是简单的
采取了分一次组的做法。

对m个长度为k的有序数组进行归并所用的时间复杂度为log(m)*mk，当采用n核的两阶段并行归并时花费的总时间复杂度为log(n)*mk+log(m/n)*mk/n，
大约当n的大小接近log(m)的时候可以取得最好的效果。

# 程序说明

## 构建

```
$ go build
```

## 测试

```
$ go test
```

## 用法

### 创建测试数据

```
$ merge_blocks generate test_data 100 1000000 # 创建test_data目录并在其下创建100个大小为1000000字节的数据块
```

### 运行两阶段排序

```
$ BUFFER_SIZE=1024 MAX_BATCH_SIZE=1048576 NUM_CORES=8 merge_blocks twopass test_data out
$ # 从test_data文件夹读取数据块并将结果输出到out；每个数据块的缓存设置为1024B，第一次合并时的最大大小设置为1MB，并行归并算法的并行度设置为8
```

### 运行一次外部排序

```
$ BUFFER_SIZE=1024 merge_blocks onepass test_data out # 从test_data文件夹读取数据块并将结果输出到out；每个数据块的缓存设置为1024B
```

# 测试

因为硬件条件限制没有还原题目条件测试，这里使用最高读写速度约为30MB/s的机械硬盘进行测试，数据为10000个100KB的数据块（总大小1GB），测试得到
的运行结果如下

|缓存大小|内存限制|排序策略|参数设置|总时间|
|-------|------|-------|------|-----|
|100B |1MB   |onepass|BUFFER_SIZE=100|2m1s  |
|1000B|1MB   |twopass|BUFFER_SIZE=500 NUM_CORES=8 MAX_BATCH_SIZE=500000|1m46s |
|1000B|10MB  |onepass|BUFFER_SIZE=1000|1m8s |
|10000B|10MB |twopass|BUFFER_SIZE=5000 NUM_CORES=8 MAX_BATCH_SIZE=5000000|1m23s|
|10000B|10MB |twopass|BUFFER_SIZE=5000 NUM_CORES=2 MAX_BATCH_SIZE=5000000|1m24s|
|10000B|10MB |twopass|BUFFER_SIZE=5000 NUM_CORES=1 MAX_BATCH_SIZE=5000000|1m33s|

从表格的数据我们可以大致做出如下结论：

- 和最初的分析一致，选用两阶段排序或者一次排序的主要标准为缓存大小对硬盘读取速度的影响，具体选用哪种方式则需要根据硬件的实际参数（读写命令
延迟、读写速度）来决定。
- 并发的归并排序相对于单核的归并排序有一定的提升，但瓶颈主要还是在于硬盘读写。

# 后续优化

- `FileReader`和`FileWriter`只是简单的使用了`bufio`进行缓存，当缓存读完的时候读取操作依然会阻塞等待IO操作完成，实际上IO操作可以
挪到后台进行，每次在缓存消费到一定程度时在后台*提前*进行后续内容的读取，达到IO和CPU计算并行的目的。虽然武断的决定了IO时间必然大于CPU时间，但
将IO和CPU并行进行还是应当可以取得一定提升的。
- 归并排序的过程中理论上上可以通过回收输入的数组已经读取了的部分的内存的方法达到只使用很少的额外内存空间，这方面可以进行优化来做到在第一阶段
中每次合并出更大的数据块。并发的归并排序也可以分多次进行数组的合并（每次合并更少的数组数量，增加并发的粒度，避免使用堆带来的额外开销），这样
会增加访存的次数，其实际的效果还需要进一步验证。
